{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 40cpProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NUcUCkr4VPSIUGew-8laZh_lZAnXR3jb",
      "authorship_tag": "ABX9TyNE5lgD3TwuhDliL+ELEYlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobby838/hello-world/blob/master/40cpProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAccuho_vk6e"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gGelDBvkk9"
      },
      "source": [
        "import argparse, os, pickle, time, math, torch, sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import Parameter\n",
        "from functools import wraps\n",
        "from datetime import datetime\n",
        "from io import open\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIx-aoKxWs1L"
      },
      "source": [
        "Old RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7iX1rCuWKB6"
      },
      "source": [
        "\n",
        "class Old_model(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
        "        super(Old_model, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        # Optionally tie weights as in:\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        # and\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
        "        # https://arxiv.org/abs/1611.01462\n",
        "        if tie_weights:\n",
        "            if nhid != ninp:\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSY-cMDhWwib"
      },
      "source": [
        "Enhanced model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b63K7V84WQtJ"
      },
      "source": [
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\" LSTM language model which uses pre-trained word vector representations\n",
        "        as encoding.\n",
        "\n",
        "        Args:\n",
        "            encoding_size: The dimensions of the word representations.\n",
        "            hidden_size: The number of features in the hidden state\n",
        "            num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
        "                would mean stacking two LSTMs/GRUs together to form a `stacked RNN`,\n",
        "                with the second RNN taking in outputs of the first RNN and\n",
        "                computing the final results. Default: 1\n",
        "            decoupled: whether there is a linear layer between the top most RNN\n",
        "                layer and the output. Default: True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoding_size, hidden_size, output_size, num_layers,\n",
        "                 encoder, rnn_type='LSTM', dropout=0, decoupled=True):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        # self.encoder = nn.Embedding(ntoken, encoding_size)\n",
        "        self.encoder = encoder\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(encoding_size, hidden_size, num_layers, dropout=dropout)\n",
        "        else:\n",
        "            raise ValueError( \"An invalid option for rnn_type was supplied, \"\n",
        "                              \"options are ['LSTM', 'GRU']\")\n",
        "        # if decoupled:\n",
        "        #     self.decoder = nn.Linear(hidden_size, encoding_size)\n",
        "        # else:\n",
        "        #     self.decoder = lambda x : x\n",
        "        #     if hidden_size != encoding_size:\n",
        "        #         raise ValueError(\"When flagging decoupled as False, the \"\n",
        "        #         \"encoding_size and the hidden_size must be the same.\")\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        self.init_layer(self.decoder)\n",
        "        self.rnn_type = rnn_type\n",
        "        self.encoding_size = encoding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_layer(self, layer):\n",
        "      if hasattr(layer, \"bias\"):\n",
        "        if type(layer.bias) != type(None):\n",
        "            nn.init.zeros_(layer.bias)\n",
        "        if hasattr(layer, \"weight\"):\n",
        "            nn.init.kaiming_normal_(layer.weight)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # emb = self.drop(self.encoder(input)) -> Decide on dropout\n",
        "        emb = self.encoder(input)\n",
        "        emb = self.drop(emb)\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        # See what we put here (decoder layer or not?)\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.num_layers, bsz, self.hidden_size),\n",
        "                    weight.new_zeros(self.num_layers, bsz, self.hidden_size))\n",
        "        else:\n",
        "            return weight.new_zeros(self.num_layers, bsz, self.hidden_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ_Zwx6_uyJl"
      },
      "source": [
        "Embedded Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkf_dmNWu1_D"
      },
      "source": [
        "\n",
        "def embedded_dropout(embed, words, dropout=0.1, scale=None):\n",
        "  if dropout:\n",
        "    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(embed.weight) / (1 - dropout)\n",
        "    masked_embed_weight = mask * embed.weight\n",
        "  else:\n",
        "    masked_embed_weight = embed.weight\n",
        "  if scale:\n",
        "    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
        "\n",
        "  padding_idx = embed.padding_idx\n",
        "  if padding_idx is None:\n",
        "      padding_idx = -1\n",
        "\n",
        "  X = torch.nn.functional.embedding(words, masked_embed_weight,\n",
        "    padding_idx, embed.max_norm, embed.norm_type,\n",
        "    embed.scale_grad_by_freq, embed.sparse\n",
        "  )\n",
        "  return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HjVDKsfw8dN"
      },
      "source": [
        "Locked dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSv77vJBw9-b"
      },
      "source": [
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, dropout=0.5):\n",
        "        if not self.training or not dropout:\n",
        "            return x\n",
        "        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n",
        "        mask = Variable(m, requires_grad=False) / (1 - dropout)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJlewjjBxkY8"
      },
      "source": [
        "Weight drop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZB6MWqKxmyr"
      },
      "source": [
        "class WeightDrop(torch.nn.Module):\n",
        "    def __init__(self, module, weights, dropout=0, variational=False):\n",
        "        super(WeightDrop, self).__init__()\n",
        "        self.module = module\n",
        "        self.weights = weights\n",
        "        self.dropout = dropout\n",
        "        self.variational = variational\n",
        "        self._setup()\n",
        "\n",
        "    def widget_demagnetizer_y2k_edition(*args, **kwargs):\n",
        "        # We need to replace flatten_parameters with a nothing function\n",
        "        # It must be a function rather than a lambda as otherwise pickling explodes\n",
        "        # We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!\n",
        "        # (╯°□°）╯︵ ┻━┻\n",
        "        return\n",
        "\n",
        "    def _setup(self):\n",
        "        # Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN\n",
        "        if issubclass(type(self.module), torch.nn.RNNBase):\n",
        "            self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n",
        "\n",
        "        for name_w in self.weights:\n",
        "            print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n",
        "            w = getattr(self.module, name_w)\n",
        "            del self.module._parameters[name_w]\n",
        "            self.module.register_parameter(name_w + '_raw', Parameter(w.data))\n",
        "\n",
        "    def _setweights(self):\n",
        "        for name_w in self.weights:\n",
        "            raw_w = getattr(self.module, name_w + '_raw')\n",
        "            w = None\n",
        "            if self.variational:\n",
        "                mask = torch.autograd.Variable(torch.ones(raw_w.size(0), 1))\n",
        "                if raw_w.is_cuda: mask = mask.cuda()\n",
        "                mask = torch.nn.functional.dropout(mask, p=self.dropout, training=True)\n",
        "                w = mask.expand_as(raw_w) * raw_w\n",
        "            else:\n",
        "                w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n",
        "            if not self.training:\n",
        "                w = w.data\n",
        "            setattr(self.module, name_w, w)\n",
        "\n",
        "    def forward(self, *args):\n",
        "        self._setweights()\n",
        "        return self.module.forward(*args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWkQ0LDdCuZQ"
      },
      "source": [
        "Ready function SplitCrossEntrophyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFeH4i6QEP9R"
      },
      "source": [
        "class SplitCrossEntropyLoss(nn.Module):\n",
        "    r'''SplitCrossEntropyLoss calculates an approximate softmax'''\n",
        "    def __init__(self, hidden_size, splits, verbose=False):\n",
        "        # We assume splits is [0, split1, split2, N] where N >= |V|\n",
        "        # For example, a vocab of 1000 words may have splits [0] + [100, 500] + [inf]\n",
        "        super(SplitCrossEntropyLoss, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.splits = [0] + splits + [100 * 1000000]\n",
        "        self.nsplits = len(self.splits) - 1\n",
        "        self.stats = defaultdict(list)\n",
        "        self.verbose = verbose\n",
        "        # Each of the splits that aren't in the head require a pretend token, we'll call them tombstones\n",
        "        # The probability given to this tombstone is the probability of selecting an item from the represented split\n",
        "        if self.nsplits > 1:\n",
        "            self.tail_vectors = nn.Parameter(torch.zeros(self.nsplits - 1, hidden_size))\n",
        "            self.tail_bias = nn.Parameter(torch.zeros(self.nsplits - 1))\n",
        "\n",
        "    def logprob(self, weight, bias, hiddens, splits=None, softmaxed_head_res=None, verbose=False):\n",
        "        # First we perform the first softmax on the head vocabulary and the tombstones\n",
        "        if softmaxed_head_res is None:\n",
        "            start, end = self.splits[0], self.splits[1]\n",
        "            head_weight = None if end - start == 0 else weight[start:end]\n",
        "            head_bias = None if end - start == 0 else bias[start:end]\n",
        "            # We only add the tombstones if we have more than one split\n",
        "            if self.nsplits > 1:\n",
        "                head_weight = self.tail_vectors if head_weight is None else torch.cat([head_weight, self.tail_vectors])\n",
        "                head_bias = self.tail_bias if head_bias is None else torch.cat([head_bias, self.tail_bias])\n",
        "\n",
        "            # Perform the softmax calculation for the word vectors in the head for all splits\n",
        "            # We need to guard against empty splits as torch.cat does not like random lists\n",
        "            head_res = torch.nn.functional.linear(hiddens, head_weight, bias=head_bias)\n",
        "            softmaxed_head_res = torch.nn.functional.log_softmax(head_res, dim=-1)\n",
        "\n",
        "        if splits is None:\n",
        "            splits = list(range(self.nsplits))\n",
        "\n",
        "        results = []\n",
        "        running_offset = 0\n",
        "        for idx in splits:\n",
        "\n",
        "            # For those targets in the head (idx == 0) we only need to return their loss\n",
        "            if idx == 0:\n",
        "                results.append(softmaxed_head_res[:, :-(self.nsplits - 1)])\n",
        "\n",
        "            # If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)\n",
        "            else:\n",
        "                start, end = self.splits[idx], self.splits[idx + 1]\n",
        "                tail_weight = weight[start:end]\n",
        "                tail_bias = bias[start:end]\n",
        "\n",
        "                # Calculate the softmax for the words in the tombstone\n",
        "                tail_res = torch.nn.functional.linear(hiddens, tail_weight, bias=tail_bias)\n",
        "\n",
        "                # Then we calculate p(tombstone) * p(word in tombstone)\n",
        "                # Adding is equivalent to multiplication in log space\n",
        "                head_entropy = (softmaxed_head_res[:, -idx]).contiguous()\n",
        "                tail_entropy = torch.nn.functional.log_softmax(tail_res, dim=-1)\n",
        "                results.append(head_entropy.view(-1, 1) + tail_entropy)\n",
        "\n",
        "        if len(results) > 1:\n",
        "            return torch.cat(results, dim=1)\n",
        "        return results[0]\n",
        "\n",
        "    def split_on_targets(self, hiddens, targets):\n",
        "        # Split the targets into those in the head and in the tail\n",
        "        split_targets = []\n",
        "        split_hiddens = []\n",
        "\n",
        "        # Determine to which split each element belongs (for each start split value, add 1 if equal or greater)\n",
        "        # This method appears slower at least for WT-103 values for approx softmax\n",
        "        #masks = [(targets >= self.splits[idx]).view(1, -1) for idx in range(1, self.nsplits)]\n",
        "        #mask = torch.sum(torch.cat(masks, dim=0), dim=0)\n",
        "        ###\n",
        "        # This is equally fast for smaller splits as method below but scales linearly\n",
        "        mask = None\n",
        "        for idx in range(1, self.nsplits):\n",
        "            partial_mask = targets >= self.splits[idx]\n",
        "            mask = mask + partial_mask if mask is not None else partial_mask\n",
        "        ###\n",
        "        #masks = torch.stack([targets] * (self.nsplits - 1))\n",
        "        #mask = torch.sum(masks >= self.split_starts, dim=0)\n",
        "        for idx in range(self.nsplits):\n",
        "            # If there are no splits, avoid costly masked select\n",
        "            if self.nsplits == 1:\n",
        "                split_targets, split_hiddens = [targets], [hiddens]\n",
        "                continue\n",
        "            # If all the words are covered by earlier targets, we have empties so later stages don't freak out\n",
        "            if sum(len(t) for t in split_targets) == len(targets):\n",
        "                split_targets.append([])\n",
        "                split_hiddens.append([])\n",
        "                continue\n",
        "            # Are you in our split?\n",
        "            tmp_mask = mask == idx\n",
        "            split_targets.append(torch.masked_select(targets, tmp_mask))\n",
        "            split_hiddens.append(hiddens.masked_select(tmp_mask.unsqueeze(1).expand_as(hiddens)).view(-1, hiddens.size(1)))\n",
        "        return split_targets, split_hiddens\n",
        "\n",
        "    def forward(self, weight, bias, hiddens, targets, verbose=False):\n",
        "        if self.verbose or verbose:\n",
        "            for idx in sorted(self.stats):\n",
        "                print('{}: {}'.format(idx, int(np.mean(self.stats[idx]))), end=', ')\n",
        "            print()\n",
        "\n",
        "        total_loss = None\n",
        "        if len(hiddens.size()) > 2: hiddens = hiddens.view(-1, hiddens.size(2))\n",
        "\n",
        "        split_targets, split_hiddens = self.split_on_targets(hiddens, targets)\n",
        "\n",
        "        # First we perform the first softmax on the head vocabulary and the tombstones\n",
        "        start, end = self.splits[0], self.splits[1]\n",
        "        head_weight = None if end - start == 0 else weight[start:end]\n",
        "        head_bias = None if end - start == 0 else bias[start:end]\n",
        "\n",
        "        # We only add the tombstones if we have more than one split\n",
        "        if self.nsplits > 1:\n",
        "            head_weight = self.tail_vectors if head_weight is None else torch.cat([head_weight, self.tail_vectors])\n",
        "            head_bias = self.tail_bias if head_bias is None else torch.cat([head_bias, self.tail_bias])\n",
        "\n",
        "        # Perform the softmax calculation for the word vectors in the head for all splits\n",
        "        # We need to guard against empty splits as torch.cat does not like random lists\n",
        "        combo = torch.cat([split_hiddens[i] for i in range(self.nsplits) if len(split_hiddens[i])])\n",
        "        ###\n",
        "        all_head_res = torch.nn.functional.linear(combo, head_weight, bias=head_bias)\n",
        "        softmaxed_all_head_res = torch.nn.functional.log_softmax(all_head_res, dim=-1)\n",
        "        if self.verbose or verbose:\n",
        "            self.stats[0].append(combo.size()[0] * head_weight.size()[0])\n",
        "\n",
        "        running_offset = 0\n",
        "        for idx in range(self.nsplits):\n",
        "            # If there are no targets for this split, continue\n",
        "            if len(split_targets[idx]) == 0: continue\n",
        "\n",
        "            # For those targets in the head (idx == 0) we only need to return their loss\n",
        "            if idx == 0:\n",
        "                softmaxed_head_res = softmaxed_all_head_res[running_offset:running_offset + len(split_hiddens[idx])]\n",
        "                entropy = -torch.gather(softmaxed_head_res, dim=1, index=split_targets[idx].view(-1, 1))\n",
        "            # If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)\n",
        "            else:\n",
        "                softmaxed_head_res = softmaxed_all_head_res[running_offset:running_offset + len(split_hiddens[idx])]\n",
        "\n",
        "                if self.verbose or verbose:\n",
        "                    start, end = self.splits[idx], self.splits[idx + 1]\n",
        "                    tail_weight = weight[start:end]\n",
        "                    self.stats[idx].append(split_hiddens[idx].size()[0] * tail_weight.size()[0])\n",
        "\n",
        "                # Calculate the softmax for the words in the tombstone\n",
        "                tail_res = self.logprob(weight, bias, split_hiddens[idx], splits=[idx], softmaxed_head_res=softmaxed_head_res)\n",
        "\n",
        "                # Then we calculate p(tombstone) * p(word in tombstone)\n",
        "                # Adding is equivalent to multiplication in log space\n",
        "                head_entropy = softmaxed_head_res[:, -idx]\n",
        "                # All indices are shifted - if the first split handles [0,...,499] then the 500th in the second split will be 0 indexed\n",
        "                indices = (split_targets[idx] - self.splits[idx]).view(-1, 1)\n",
        "                # Warning: if you don't squeeze, you get an N x 1 return, which acts oddly with broadcasting\n",
        "                tail_entropy = torch.gather(torch.nn.functional.log_softmax(tail_res, dim=-1), dim=1, index=indices).squeeze()\n",
        "                entropy = -(head_entropy + tail_entropy)\n",
        "            ###\n",
        "            running_offset += len(split_hiddens[idx])\n",
        "            total_loss = entropy.float().sum() if total_loss is None else total_loss + entropy.float().sum()\n",
        "\n",
        "        return (total_loss / len(targets)).type_as(weight)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzjxDNfWj7Ri"
      },
      "source": [
        "AWD_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wNS_rD9j62P"
      },
      "source": [
        "\n",
        "class AWDRNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, dropouth=0.5, dropouti=0.5, dropoute=0.1, wdrop=0, tie_weights=False):\n",
        "        super(AWDRNNModel, self).__init__()\n",
        "        self.lockdrop = LockedDropout()\n",
        "        self.idrop = nn.Dropout(dropouti)\n",
        "        self.hdrop = nn.Dropout(dropouth)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        assert rnn_type in ['LSTM', 'QRNN', 'GRU'], 'RNN type is not supported'\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnns = [torch.nn.LSTM(ninp if l == 0 else nhid, nhid if l != nlayers - 1 else (ninp if tie_weights else nhid), 1, dropout=0) for l in range(nlayers)]\n",
        "            if wdrop:\n",
        "                self.rnns = [WeightDrop(rnn, ['weight_hh_l0'], dropout=wdrop) for rnn in self.rnns]\n",
        "        print(\"AWD \", self.rnns)\n",
        "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        if tie_weights:\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.ninp = ninp\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "        self.dropout = dropout\n",
        "        self.dropouti = dropouti\n",
        "        self.dropouth = dropouth\n",
        "        self.dropoute = dropoute\n",
        "        self.tie_weights = tie_weights\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.fill_(0)\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, return_h=False):\n",
        "        emb = embedded_dropout(self.encoder, input, dropout=self.dropoute if self.training else 0)\n",
        "\n",
        "        emb = self.lockdrop(emb, self.dropouti)\n",
        "\n",
        "        raw_output = emb\n",
        "        new_hidden = []\n",
        "\n",
        "        raw_outputs = []\n",
        "        outputs = []\n",
        "        for l, rnn in enumerate(self.rnns):\n",
        "            current_input = raw_output\n",
        "            raw_output, new_h = rnn(raw_output, hidden[l])\n",
        "            new_hidden.append(new_h)\n",
        "            raw_outputs.append(raw_output)\n",
        "            if l != self.nlayers - 1:\n",
        "                raw_output = self.lockdrop(raw_output, self.dropouth)\n",
        "                outputs.append(raw_output)\n",
        "        hidden = new_hidden\n",
        "\n",
        "        output = self.lockdrop(raw_output, self.dropout)\n",
        "        outputs.append(output)\n",
        "\n",
        "        result = output.view(output.size(0)*output.size(1), output.size(2))\n",
        "        if return_h:\n",
        "            return result, hidden, raw_outputs, outputs\n",
        "        return result, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return [(weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else self.nhid)).zero_(),\n",
        "                    weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else self.nhid)).zero_())\n",
        "                    for l in range(self.nlayers)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zge2z756f8IT"
      },
      "source": [
        "AWD-LSTM with pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quxMvATzgCrX"
      },
      "source": [
        "class EAWDRNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "    def __init__(self, rnn_type, ntoken, encoder, nhid, nlayers, dropout=0.5, dropouth=0.5, dropouti=0.5, dropoute=0.1, wdrop=0, tie_weights=False):\n",
        "        super(EAWDRNNModel, self).__init__()\n",
        "        self.lockdrop = LockedDropout()\n",
        "        self.idrop = nn.Dropout(dropouti)\n",
        "        self.hdrop = nn.Dropout(dropouth)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        #self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.encoder = encoder\n",
        "        assert rnn_type in ['LSTM', 'QRNN', 'GRU'], 'RNN type is not supported'\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnns = [torch.nn.LSTM(encoder.encoding_size if l == 0 else nhid, nhid if l != nlayers - 1 else (encoder.encoding_size if tie_weights else nhid), 1, dropout=0) for l in range(nlayers)]\n",
        "            if wdrop:\n",
        "                self.rnns = [WeightDrop(rnn, ['weight_hh_l0'], dropout=wdrop) for rnn in self.rnns]\n",
        "        print(\"AWD \", self.rnns)\n",
        "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "        self.init_layer(self.decoder)\n",
        "        if tie_weights:\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        #self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        #self.ninp = ninp\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "        self.dropout = dropout\n",
        "        self.dropouti = dropouti\n",
        "        self.dropouth = dropouth\n",
        "        self.dropoute = dropoute\n",
        "        self.tie_weights = tie_weights\n",
        "\n",
        "    def init_layer(self, layer):\n",
        "        if hasattr(layer, \"bias\"):\n",
        "            if type(layer.bias) != type(None):\n",
        "                nn.init.zeros_(layer.bias)\n",
        "        if hasattr(layer, \"weight\"):\n",
        "            nn.init.kaiming_normal_(layer.weight)\n",
        "\n",
        "    def forward(self, input, hidden, return_h=False):\n",
        "        emb = self.encoder(input)\n",
        "        emb = self.drop(emb)\n",
        "        #emb = embedded_dropout(self.encoder, input, dropout=self.dropoute if self.training else 0)\n",
        "\n",
        "        #emb = self.lockdrop(emb, self.dropouti)\n",
        "        raw_output = emb\n",
        "        new_hidden = []\n",
        "\n",
        "        raw_outputs = []\n",
        "        outputs = []\n",
        "        for l, rnn in enumerate(self.rnns):\n",
        "            current_input = raw_output\n",
        "            raw_output, new_h = rnn(raw_output, hidden[l])\n",
        "            new_hidden.append(new_h)\n",
        "            raw_outputs.append(raw_output)\n",
        "            if l != self.nlayers - 1:\n",
        "                raw_output = self.lockdrop(raw_output, self.dropouth)\n",
        "                outputs.append(raw_output)\n",
        "        hidden = new_hidden\n",
        "\n",
        "        output = self.lockdrop(raw_output, self.dropout)\n",
        "        outputs.append(output)\n",
        "\n",
        "        result = output.view(output.size(0)*output.size(1), output.size(2))\n",
        "        if return_h:\n",
        "            return result, hidden, raw_outputs, outputs\n",
        "        return result, hidden\n",
        "    \n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return [(weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else encoder.encoding_size)).zero_(),\n",
        "                    weight.new(1, bsz, self.nhid if l != self.nlayers - 1 else (self.ninp if self.tie_weights else encoder.encoding_size)).zero_())\n",
        "                    for l in range(self.nlayers)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoxAZsPnW4Mi"
      },
      "source": [
        "Data loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3otjJbgBWpyh"
      },
      "source": [
        "\n",
        "class Corpus(object):\n",
        "    \"\"\" Object to tokenize and store the text corpus\n",
        "\n",
        "        path: path to the directory with the training, validation and test\n",
        "            datasets ('train.txt','valid.txt','test.txt')\n",
        "        embedding: gensim KeyedVectors object.\n",
        "        vocab: dictionary from word to index (should contain all words in the\n",
        "            vocabulary, with the ones with vector representations first).\n",
        "        vectors: vector representations.\n",
        "        load: whether to load the vocab and vectors, or derive from traing\n",
        "            corpora. If true, vocab and vectors must be provided, otherwise,\n",
        "            embedding should be provided.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, embedding=None, vocab=None, vectors=None,\n",
        "                load=False, portion=1):\n",
        "        if load:\n",
        "            self._load(vocab,vectors)\n",
        "        else:\n",
        "            self.narrow_vocab(os.path.join(path, 'train.txt'), embedding)\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'), portion)\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def _load(self, vocab, vectors):\n",
        "        self.vocab = vocab\n",
        "        self.vectors = vectors\n",
        "\n",
        "    def narrow_vocab(self, path, embeddings):\n",
        "        \"\"\" Find the vocabulary of the train dataset and make the vocabulary of\n",
        "            the embedding the same.\n",
        "        \"\"\"\n",
        "        assert os.path.exists(path)\n",
        "\n",
        "        # Find all the distinct words in the file.\n",
        "        vocabulary = set()\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                [vocabulary.add(word) for word in words if not word in vocabulary]\n",
        "\n",
        "        # Find words in embedding and words not in it.\n",
        "        emb_vocab = {}\n",
        "        vocab_out = {}\n",
        "        vectors = []\n",
        "        for word in vocabulary:\n",
        "            if word in embeddings.vocab:\n",
        "                emb_vocab[word] = len(emb_vocab)\n",
        "                vectors.append(embeddings.vectors[embeddings.vocab[word].index])\n",
        "            else:\n",
        "                vocab_out[word] = len(vocab_out)\n",
        "        l = len(emb_vocab)\n",
        "        # Create a single dictionary from word to its index.\n",
        "        emb_vocab.update({key: value + l for key, value in vocab_out.items()})\n",
        "        self.vocab = emb_vocab\n",
        "        self.vectors = vectors\n",
        "\n",
        "    def tokenize(self, path, portion=1):\n",
        "        \"\"\" Returns the word indices for a text file (dataset) \"\"\"\n",
        "        assert os.path.exists(path)\n",
        "\n",
        "        word2idx = lambda x: self.vocab[x]\n",
        "\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            num_lines = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = [word2idx(word) for word in words]\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "                num_lines += 1\n",
        "            ids = torch.cat(idss[:int(num_lines * portion)])\n",
        "\n",
        "        return ids\n",
        "\n",
        "\n",
        "def batchify(data, bsz, device):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "def get_batch(source, i, seq_len=50):\n",
        "    seq_len = min(seq_len, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq_mTH9oXJKA"
      },
      "source": [
        "Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu4e9FJnXLyS"
      },
      "source": [
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    \"\"\" Word encoder. If the word already has a representation, returns that\n",
        "        plus the output of the linear with input 0-tensor. If the word\n",
        "        doesn't have a representation, returns default with the output of\n",
        "        the linear with input a one-hot vector for that word.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, vocab_size, vectors, default='zero'):\n",
        "        \"\"\" size: number of units in the linear layer.\n",
        "\n",
        "            vocab_size: number of words in the vocabulary.\n",
        "\n",
        "            vectors: transfer learning vector representation for the first words\n",
        "            in the vocabulary, in order.\n",
        "\n",
        "            default: representation for the vectors part when the word doesn't\n",
        "            have a pre-trained vector representation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        vectors = torch.tensor(vectors)\n",
        "        self.input_size = vocab_size - len(vectors)\n",
        "        assert self.input_size > 0\n",
        "        self.hidden_size = size\n",
        "        self.size = size\n",
        "        self.encoding_size = self.hidden_size + vectors.shape[1]\n",
        "        self.linear = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.init_layer(self.linear)\n",
        "\n",
        "        defaults = torch.zeros((self.input_size, vectors.shape[1]))\n",
        "        self.vectors = torch.cat((vectors, defaults), 0)\n",
        "\n",
        "        defaults = torch.zeros((vocab_size - self.input_size, self.input_size))\n",
        "        one_hot = torch.zeros((self.input_size, self.input_size))\n",
        "        # add the ones\n",
        "        one_hot = one_hot.scatter(1,\n",
        "                  torch.tensor([[i] for i in range(self.input_size)]), 1)\n",
        "        self.linear_inputs = torch.cat((defaults, one_hot), 0)\n",
        "\n",
        "\n",
        "\n",
        "    def encode1(self, inputs):\n",
        "        return F.embedding(inputs, self.vectors)\n",
        "\n",
        "    def encode2(self, inputs):\n",
        "        return F.embedding(inputs, self.linear_inputs)\n",
        "\n",
        "    def forward(self, batch):\n",
        "         x1 = self.encode1(batch)\n",
        "         x2 = self.encode2(batch)\n",
        "         x2 = self.linear(x2)\n",
        "         return torch.cat((x1,x2),-1)\n",
        "\n",
        "    def init_layer(self, layer):\n",
        "      if hasattr(layer, \"bias\"):\n",
        "        if type(layer.bias) != type(None):\n",
        "            torch.nn.init.zeros_(layer.bias)\n",
        "        if hasattr(layer, \"weight\"):\n",
        "            torch.nn.init.kaiming_normal_(layer.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0cx_GvfXnop"
      },
      "source": [
        "train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knJJsukZXpgx"
      },
      "source": [
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "class Trainer():\n",
        "\n",
        "    def __init__(self, model, corpus, criterion, device, logger = None,\n",
        "                 batch_size = 25, seq_len = 35, learning_rate = 20,\n",
        "                 log_interval=100, clip_grad= 0.25):\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.criterion = criterion\n",
        "        self.train_data = batchify(corpus.train, batch_size, device)\n",
        "        self.corpus = corpus\n",
        "        self.epoch = -1\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "        self.learning_rate = learning_rate\n",
        "        self.log_interval = log_interval\n",
        "        self.clip_grad = clip_grad\n",
        "        if logger == None:\n",
        "            self.logging = False\n",
        "            self.logger = None\n",
        "        else:\n",
        "            self.logging = True\n",
        "            self.logger = logger\n",
        "\n",
        "    def train(self):\n",
        "        self.epoch += 1\n",
        "        self.model.train()\n",
        "        total_loss = 0.\n",
        "        start_time = time.time()\n",
        "        number_tokens = len(self.corpus.vocab)\n",
        "        hidden = self.model.init_hidden(self.batch_size)\n",
        "\n",
        "        for batch, i in enumerate(range(0, self.train_data.size(0) - 1, self.seq_len)):\n",
        "            data, targets = get_batch(self.train_data, i, seq_len=self.seq_len)\n",
        "            # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "            # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "            self.model.zero_grad()\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output, hidden = self.model(data, hidden)\n",
        "            loss = self.criterion(output.view(-1, number_tokens), targets.long())\n",
        "            loss.backward()\n",
        "\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad)\n",
        "            for p in self.model.parameters():\n",
        "                p.data.add_(-self.learning_rate, p.grad.data) # Is this just Stochastic Gradient Descent?\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch % self.log_interval == 0 and batch > 0:\n",
        "                cur_loss = total_loss / self.log_interval\n",
        "                elapsed = time.time() - start_time\n",
        "                print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                        'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    self.epoch, batch, len(self.train_data) // self.seq_len,\n",
        "                    self.learning_rate, elapsed * 1000 / self.log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "                if self.logging:\n",
        "                    self.logger.log_train(self.epoch, batch, cur_loss)\n",
        "                total_loss = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(model, corpus, criterion, device, batch_size = 10, seq_len = 35,\n",
        "             set = 'valid'):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.vocab)\n",
        "    data_source = batchify(getattr(corpus,set), batch_size, device)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, seq_len):\n",
        "            data, targets = get_batch(data_source, i, seq_len=seq_len)\n",
        "            output, hidden = model(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets.long()).item()\n",
        "    return total_loss / (len(data_source) - 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEMEaO47XbJX"
      },
      "source": [
        "Training for AWDLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSuerZ4RXfkW"
      },
      "source": [
        "class AWDTrainer():\n",
        "\n",
        "    def __init__(self, model, corpus, criterion, optimizer, device, logger = None,\n",
        "                 batch_size = 80, bptt = 70,\n",
        "                 alpha = 2, beta = 1, log_interval=100, clip_grad= 0.25):\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_data = batchify(corpus.train, batch_size, device)\n",
        "        self.corpus = corpus\n",
        "        self.epoch = -1\n",
        "        self.batch_size = batch_size\n",
        "        self.bptt = bptt\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.log_interval = log_interval\n",
        "        self.clip_grad = clip_grad\n",
        "\n",
        "    def train(self):\n",
        "        # Turn on training mode which enables dropout.\n",
        "        self.epoch += 1\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        ntokens = len(self.corpus.vocab)\n",
        "        hidden = self.model.init_hidden(self.batch_size)\n",
        "        batch, i = 0, 0\n",
        "        while i < self.train_data.size(0) - 1 - 1:\n",
        "            tmp = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n",
        "            # Prevent excessively small or negative sequence lengths\n",
        "            seq_len = max(5, int(np.random.normal(tmp, 5)))\n",
        "            # There's a very small chance that it could select a very long sequence length resulting in OOM\n",
        "            # seq_len = min(seq_len, args.bptt + 10)\n",
        "\n",
        "            lr2 = self.optimizer.param_groups[0]['lr']\n",
        "            self.optimizer.param_groups[0]['lr'] = lr2 * seq_len / self.bptt\n",
        "            self.model.train()\n",
        "            data, targets = get_batch(self.train_data, i, seq_len=seq_len)\n",
        "            # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "            # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            output, hidden, rnn_hs, dropped_rnn_hs = model(data, hidden, return_h=True)\n",
        "            raw_loss = criterion(model.decoder.weight, model.decoder.bias, output, targets)\n",
        "\n",
        "            loss = raw_loss\n",
        "            # Activiation Regularization\n",
        "            if self.alpha: loss = loss + sum(self.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs[-1:])\n",
        "            # Temporal Activation Regularization (slowness)\n",
        "            if self.beta: loss = loss + sum(self.beta * (rnn_h[1:] - rnn_h[:-1]).pow(2).mean() for rnn_h in rnn_hs[-1:])\n",
        "            loss.backward()\n",
        "\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            if self.clip_grad: torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += raw_loss.data\n",
        "            self.optimizer.param_groups[0]['lr'] = lr2\n",
        "            if batch % self.log_interval == 0 and batch > 0:\n",
        "                cur_loss = total_loss.item() / self.log_interval\n",
        "                elapsed = time.time() - start_time\n",
        "                print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '\n",
        "                        'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'.format(\n",
        "                    self.epoch, batch, len(self.train_data) // self.bptt, self.optimizer.param_groups[0]['lr'],\n",
        "                    elapsed * 1000 / self.log_interval, cur_loss, math.exp(cur_loss), cur_loss / math.log(2)))\n",
        "                total_loss = 0\n",
        "                start_time = time.time()\n",
        "            ###\n",
        "            batch += 1\n",
        "            i += seq_len\n",
        "\n",
        "def awdevaluate(model, corpus, criterion, device, batch_size=10, bptt = 70):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    ntokens = len(corpus.vocab)\n",
        "    data_source = batchify(corpus.valid, batch_size, device)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    for i in range(0, data_source.size(0) - 1, bptt):\n",
        "        data, targets = get_batch(data_source, i, seq_len=bptt)\n",
        "        output, hidden = model(data, hidden)\n",
        "        total_loss += len(data) * criterion(model.decoder.weight, model.decoder.bias, output, targets).data\n",
        "        hidden = repackage_hidden(hidden)\n",
        "    return total_loss.item() / len(data_source)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRnT_kk3XSXZ"
      },
      "source": [
        "Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqaKXsZiXT-R"
      },
      "source": [
        "\n",
        "def save_checkpoint(model, path, valid_loss, args={}):\n",
        "    if path:\n",
        "        to_save = {'params' : model.state_dict(), 'valid_loss': valid_loss,\n",
        "                   'args': args}\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(to_save, f)\n",
        "        print('checkpoint saved to {}'.format(path))\n",
        "\n",
        "def load_checkpoint(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = pickle.load(f)\n",
        "    return checkpoint\n",
        "\n",
        "class Logger(object):\n",
        "\n",
        "    def __init__(self, path):\n",
        "        self.create_files(path)\n",
        "\n",
        "    def create_files(self, path):\n",
        "        if not os.path.exists(path):\n",
        "            raise RuntimeError(\"the folder {} doesn't exist.\")\n",
        "        self.base_path = path\n",
        "        self.train_log_file = os.path.join(path, 'train.csv')\n",
        "        self.valid_log_file = os.path.join(path,'valid.csv')\n",
        "        with open(self.train_log_file, 'w') as f:\n",
        "            f.write(\"epoch,batches,time,loss,perplexity\\n\")\n",
        "            f.write(\"nan,nan,{},nan,nan\\n\".format(time.time()))\n",
        "        with open(self.valid_log_file,'w') as f:\n",
        "            f.write(\"epoch,time,loss,perplexity\\n\")\n",
        "            f.write(\"nan,{},nan,nan\\n\".format(time.time()))\n",
        "\n",
        "    def log_valid(self, epoch, loss):\n",
        "        line = '{},{},{},{}\\n'.format(epoch, time.time(), loss, math.exp(loss))\n",
        "        with open(self.valid_log_file, 'a') as f:\n",
        "            f.write(line)\n",
        "\n",
        "    def log_train(self, epoch, batches, loss):\n",
        "        line = '{},{},{},{},{}\\n'.format(epoch, batches, time.time(),\n",
        "                                         loss, math.exp(loss))\n",
        "        with open(self.train_log_file, 'a') as f:\n",
        "            f.write(line)\n",
        "\n",
        "    def log_description(self, args):\n",
        "        path = os.path.join(self.base_path, 'description.txt')\n",
        "        args = args.__dict__\n",
        "        with open(path, 'w') as fout:\n",
        "            fout.write(str(datetime.now()) + '\\n\\n')\n",
        "            for key, val in args.items():\n",
        "                fout.write('{}: {}\\n'.format(key,val))\n",
        "\n",
        "\n",
        "def load_model_corpora(checkpoint):\n",
        "    \"\"\" Load the model the checkpoint pointed at by `checkpoint' is for and the\n",
        "        corpora indicated in the arguments within the checkpoint.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        checkpoint = load_checkpoint(checkpoint)\n",
        "        args = checkpoint['args']\n",
        "        params = checkpoint['params']\n",
        "    except Exception as e:\n",
        "        print('The following exception ocurred:')\n",
        "        print(e)\n",
        "        raise RuntimeError('The first object in checkpoint must be a '\n",
        "              'dictionary containing at least [args,params].')\n",
        "    # Use the arguments to create a model that is the same as the one we have\n",
        "    # the parameters for.\n",
        "    if args.load:\n",
        "        with open(args.load,'rb') as f:\n",
        "            stored_dict = pickle.load(f)\n",
        "        corpora = Corpus(args.corpus,load=True,vocab=stored_dict['vocabulary'],\n",
        "                   vectors=stored_dict['vectors'])\n",
        "    else:\n",
        "        # I never do load = False.\n",
        "        corpora = None\n",
        "    # create a binary pickle file \n",
        "    #f = open(\"drive/MyDrive/chekpoints/ptb.pkl\",\"wb\")\n",
        "\n",
        "    # write the python object (dict) to pickle file\n",
        "    #pickle.dump(corpora,f)\n",
        "\n",
        "    # close file\n",
        "    #f.close()\n",
        "\n",
        "    if args.model == 'OLDLSTM':\n",
        "        model = Old_model('LSTM', len(corpora.vocab), args.encoder_size,\n",
        "                    args.hidden_size, args.layers, args.dropout)\n",
        "    elif args.model == 'LSTM':\n",
        "        encoder = Encoder(50, len(corpora.vocab), corpora.vectors)\n",
        "        model = RNNModel(encoder.encoding_size, args.hidden_size,\n",
        "                    len(corpora.vocab), args.layers, encoder, dropout=args.dropout)\n",
        "    elif args.model == 'AWDLSTM':\n",
        "        model = AWDRNNModel('LSTM', len(corpora.vocab), args.hidden_size, args.layers, encoder,\n",
        "                            args.dropout, args.dropouth, args.dropouti, args.dropoute, args.wdrop, args.tied)\n",
        "    elif args.model == 'EAWDLSTM':\n",
        "        encoder = Encoder(50, len(corpora.vocab), corpora.vectors)\n",
        "        model = EAWDRNNModel('LSTM', len(corpora.vocab), encoder, \n",
        "                            args.hidden_size, args.layers, args.dropout, args.dropouth, args.dropouti, args.dropoute, args.wdrop, args.tied)\n",
        "    # load the parameters from checkpoint\n",
        "    model.load_state_dict(params)\n",
        "    return model, corpora\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIbdcNEZZsGT"
      },
      "source": [
        "Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_Ro2HiZtvC",
        "outputId": "47477112-d997-4e6b-8ce3-60acb0616176"
      },
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "    description=\"In the future, train a LSTM language model using word embeddings.\",\n",
        "    formatter_class=argparse.ArgumentDefaultsHelpFormatter,)\n",
        "parser.add_argument(\n",
        "    \"--corpus\", default=\"drive/MyDrive/ptb/\", type=str,\n",
        "    help=\"Path where train.txt, valid.txt and test.txt are contained.\")\n",
        "parser.add_argument(\"--embedding-path\", default=\"drive/MyDrive/vectors.bin\", type=str,\n",
        "                    help=\"Path for the binary file containing the embeddings.\")\n",
        "parser.add_argument(\"--epochs\", default=20, type=int,\n",
        "                    help='Number of epochs to train for.')\n",
        "parser.add_argument(\"--lr\", default=20, type=int, help='learning rate.')\n",
        "parser.add_argument(\"--batch-size\", default=64, type=int,\n",
        "                    help='Number of batches to divide the data in.')\n",
        "parser.add_argument(\"--seq-len\", default=35, type=int,\n",
        "                    help='length of the training sequences (backpropagation through time'\n",
        "                    'will be truncated to this number of steps).')\n",
        "parser.add_argument(\"--dropout\", default=0.5, type=float,\n",
        "                     help='dropout of the network.')\n",
        "parser.add_argument('--dropouth', type=float, default=0.3,\n",
        "                    help='dropout for rnn layers (0 = no dropout)')\n",
        "parser.add_argument('--dropouti', type=float, default=0.65,\n",
        "                    help='dropout for input embedding layers (0 = no dropout)')\n",
        "parser.add_argument('--dropoute', type=float, default=0.1,\n",
        "                    help='dropout to remove words from embedding layer (0 = no dropout)')\n",
        "parser.add_argument('--wdrop', type=float, default=0.5,\n",
        "                    help='amount of weight dropout to apply to the RNN hidden to hidden matrix')\n",
        "parser.add_argument(\"--clip-grad\", default=0.25, type=float,\n",
        "                     help='gradient clipping.')\n",
        "parser.add_argument(\"--layers\", default=2, type=int,\n",
        "                    help='Number of stacked RNN layers.')\n",
        "parser.add_argument(\"--hidden-size\", default=350, type=int,\n",
        "                    help='The number of units each RNN layer has.')\n",
        "parser.add_argument(\"--load\", default='drive/MyDrive/chekpoints/ptb.pkl', type=str,\n",
        "                    help='If provided, the path with vocabulary and vectors.')\n",
        "parser.add_argument(\"--checkpoint\", default='drive/MyDrive/chekpoints/checkpoints.pkl', type=str,\n",
        "                    help='Path to store checkpoints of the model during training.')\n",
        "parser.add_argument(\"--log-dir\", default='drive/MyDrive/logs', type=str,\n",
        "                    help='If provided, logs will be stored in the directory.')\n",
        "parser.add_argument(\"--log-interval\", default=100, type=int,\n",
        "                    help='Number of batches between information is logged.')\n",
        "parser.add_argument(\"--model\", type=str, default='AWDLSTM',\n",
        "                    help='type of recurrent net (LSTM, AWDLSTM, OLDLSTM, EAWDLSTM)')\n",
        "parser.add_argument(\"--encoder-size\", type=int, default=350)\n",
        "parser.add_argument(\"--dataset-portion\", type=float, default=1,\n",
        "                    help=\"If provided, this is the proportion of the training \"\n",
        "                    \"set to be used in training.\")\n",
        "parser.add_argument('--alpha', type=float, default=2,\n",
        "                    help='alpha L2 regularization on RNN activation (alpha = 0 means no regularization)')\n",
        "parser.add_argument('--beta', type=float, default=1,\n",
        "                    help='beta slowness regularization applied on RNN activiation (beta = 0 means no regularization)')\n",
        "parser.add_argument('--wdecay', type=float, default=1.2e-6,\n",
        "                    help='weight decay applied to all weights')\n",
        "parser.add_argument(\"--tied\", action = 'store_true', help=\"weight tying or not\")\n",
        "parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parser.parse_args()\n",
        "    if args.log_dir:\n",
        "        logger = Logger(args.log_dir)\n",
        "        logger.log_description(args)\n",
        "    else:\n",
        "        logger = None\n",
        "    # if available use a GPU.\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "        print(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        torch.set_default_tensor_type('torch.FloatTensor')\n",
        "        print(\"cpu\")\n",
        "\n",
        "    if args.load:\n",
        "        with open(args.load,'rb') as f:\n",
        "            stored_dict = pickle.load(f)\n",
        "        corpora = Corpus(args.corpus,load=True,vocab=stored_dict['vocabulary'],\n",
        "                   vectors=stored_dict['vectors'], portion=args.dataset_portion)\n",
        "    else:\n",
        "        # Load the pre-trained embeddings\n",
        "        from gensim.models import KeyedVectors\n",
        "        embeddings = KeyedVectors.load_word2vec_format(args.embedding_path,\n",
        "                                                        binary=True)\n",
        "        # Load the corpora, find the vocabulary and what is in the embeddings.\n",
        "        corpora = Corpus(args.corpus, embeddings)\n",
        "        # Don't need the embeddings any longer. corpora has a copy of the relevant\n",
        "        # vectors.\n",
        "        del embeddings\n",
        "\n",
        "        #path = \"drive/MyDrive/chekpoints/wk2.pkl\"\n",
        "        #to_save = {'vocabulary' : corpora.vocab, 'vectors': corpora.vectors}\n",
        "        #with open(path, 'wb') as f:\n",
        "            #pickle.dump(to_save, f)\n",
        "        #print('corpora saved to {}'.format(path))\n",
        "\n",
        "    if args.model == 'OLDLSTM':\n",
        "        model = Old_model('LSTM', len(corpora.vocab), args.encoder_size,\n",
        "                    args.hidden_size, args.layers, args.dropout)\n",
        "        print(\"old\")\n",
        "    elif args.model == 'LSTM':\n",
        "        encoder = Encoder(50, len(corpora.vocab), corpora.vectors)\n",
        "        model = RNNModel(encoder.encoding_size, args.hidden_size,\n",
        "                    len(corpora.vocab), args.layers, encoder, dropout=args.dropout)\n",
        "        print(\"enhanced\")\n",
        "    elif args.model == 'AWDLSTM':\n",
        "        model = AWDRNNModel('LSTM', len(corpora.vocab), args.encoder_size, args.hidden_size, args.layers,\n",
        "                            args.dropout, args.dropouth, args.dropouti, args.dropoute, args.wdrop, args.tied)\n",
        "        print(\"AWDLSTM\")\n",
        "    elif args.model == 'EAWDLSTM' :\n",
        "        encoder = Encoder(50, len(corpora.vocab), corpora.vectors)\n",
        "        model = EAWDRNNModel('LSTM', len(corpora.vocab), encoder, \n",
        "                            args.hidden_size, args.layers, args.dropout, args.dropouth, args.dropouti, args.dropoute, args.wdrop, args.tied)\n",
        "        print(\"EAWDLSTM\")\n",
        "    lr = args.lr\n",
        "    weight_decay = args.wdecay\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = args.lr, weight_decay=args.wdecay)\n",
        "    if args.model =='AWDLSTM' or args.model == 'EAWDLSTM' :\n",
        "        splits = []\n",
        "        if len(corpora.vocab) > 500000:\n",
        "            # One Billion\n",
        "            # This produces fairly even matrix mults for the buckets:\n",
        "            # 0: 11723136, 1: 10854630, 2: 11270961, 3: 11219422\n",
        "            splits = [4200, 35000, 180000]\n",
        "        elif len(corpora.vocab) > 75000:\n",
        "            # WikiText-103\n",
        "            splits = [2800, 20000, 76000]\n",
        "        print('Using', splits)\n",
        "        if args.model == 'AWDLSTM' :\n",
        "            criterion = SplitCrossEntropyLoss(args.encoder_size, splits=splits, verbose=False)\n",
        "        elif args.model == 'EAWDLSTM' :\n",
        "            criterion = SplitCrossEntropyLoss(args.encoder_size, splits=splits, verbose=False)\n",
        "        trainer = AWDTrainer(model, corpora, criterion, optimizer, device, logger,\n",
        "                 80, 70,\n",
        "                 2, 1, args.log_interval, args.clip_grad)\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        trainer = Trainer(model, corpora, criterion, device, logger,\n",
        "                  args.batch_size, args.seq_len, args.lr, args.log_interval,\n",
        "                  args.clip_grad)\n",
        "    best_valid_loss = float(\"inf\")\n",
        "    for epoch in range(args.epochs):\n",
        "        print('Time at the start of epoch {} is {}'.format(epoch,datetime.now()))\n",
        "        trainer.train()\n",
        "        if args.model == 'AWDLSTM' or args.model == 'EAWDLSTM':\n",
        "            valid_loss = awdevaluate(model,corpora, criterion, device)\n",
        "        else :\n",
        "            valid_loss = evaluate(model,corpora, criterion, device)\n",
        "        print('Validation loss: {:.2f}. Perplexity: {:.2f}'.format(valid_loss,\n",
        "              math.exp(valid_loss)))\n",
        "        if args.log_dir:\n",
        "            logger.log_valid(epoch, valid_loss)\n",
        "        save_checkpoint(model.to(torch.device('cpu')), args.checkpoint,\n",
        "                        valid_loss, args)\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Anneal the learning rate if the validation loss hasn't improved.\n",
        "        if (valid_loss - best_valid_loss) < -0.01:\n",
        "            best_valid_loss = valid_loss\n",
        "        else:\n",
        "            if args.model == 'AWDLSTM' or args.model =='EAWDLSTM':\n",
        "                optimizer.param_groups[0]['lr'] /= 8.0\n",
        "            else :\n",
        "                trainer.learning_rate /= 4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "AWD  [WeightDrop(\n",
            "  (module): LSTM(350, 350)\n",
            "), WeightDrop(\n",
            "  (module): LSTM(350, 350)\n",
            ")]\n",
            "AWDLSTM\n",
            "Using []\n",
            "Time at the start of epoch 0 is 2021-08-23 10:58:10.611101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:680: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:924.)\n",
            "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch   0 |   100/  165 batches | lr 20.00000 | ms/batch 52.91 | loss  7.27 | ppl  1433.29 | bpc   10.485\n",
            "Validation loss: 6.42. Perplexity: 614.08\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 1 is 2021-08-23 10:58:20.471175\n",
            "| epoch   1 |   100/  165 batches | lr 20.00000 | ms/batch 53.21 | loss  6.50 | ppl   668.29 | bpc    9.384\n",
            "Validation loss: 6.13. Perplexity: 457.70\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 2 is 2021-08-23 10:58:30.363732\n",
            "| epoch   2 |   100/  165 batches | lr 20.00000 | ms/batch 53.08 | loss  6.25 | ppl   517.16 | bpc    9.014\n",
            "Validation loss: 5.93. Perplexity: 377.77\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 3 is 2021-08-23 10:58:40.195290\n",
            "| epoch   3 |   100/  165 batches | lr 20.00000 | ms/batch 53.06 | loss  6.07 | ppl   433.85 | bpc    8.761\n",
            "Validation loss: 5.83. Perplexity: 340.81\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 4 is 2021-08-23 10:58:50.058284\n",
            "| epoch   4 |   100/  165 batches | lr 20.00000 | ms/batch 53.17 | loss  5.91 | ppl   367.06 | bpc    8.520\n",
            "Validation loss: 5.62. Perplexity: 276.63\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 5 is 2021-08-23 10:58:59.953294\n",
            "| epoch   5 |   100/  165 batches | lr 20.00000 | ms/batch 52.13 | loss  5.80 | ppl   331.44 | bpc    8.373\n",
            "Validation loss: 5.51. Perplexity: 248.25\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 6 is 2021-08-23 10:59:09.804174\n",
            "| epoch   6 |   100/  165 batches | lr 20.00000 | ms/batch 51.75 | loss  5.72 | ppl   303.64 | bpc    8.246\n",
            "Validation loss: 5.43. Perplexity: 229.05\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 7 is 2021-08-23 10:59:19.677787\n",
            "| epoch   7 |   100/  165 batches | lr 20.00000 | ms/batch 52.45 | loss  5.63 | ppl   278.79 | bpc    8.123\n",
            "Validation loss: 5.38. Perplexity: 216.37\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 8 is 2021-08-23 10:59:29.562160\n",
            "| epoch   8 |   100/  165 batches | lr 20.00000 | ms/batch 52.54 | loss  5.57 | ppl   263.55 | bpc    8.042\n",
            "Validation loss: 5.31. Perplexity: 201.57\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 9 is 2021-08-23 10:59:39.411830\n",
            "| epoch   9 |   100/  165 batches | lr 20.00000 | ms/batch 53.34 | loss  5.50 | ppl   245.49 | bpc    7.940\n",
            "Validation loss: 5.27. Perplexity: 193.95\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 10 is 2021-08-23 10:59:49.251146\n",
            "| epoch  10 |   100/  165 batches | lr 20.00000 | ms/batch 52.08 | loss  5.46 | ppl   235.22 | bpc    7.878\n",
            "Validation loss: 5.21. Perplexity: 183.52\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 11 is 2021-08-23 10:59:59.131170\n",
            "| epoch  11 |   100/  165 batches | lr 20.00000 | ms/batch 53.23 | loss  5.41 | ppl   223.74 | bpc    7.806\n",
            "Validation loss: 5.18. Perplexity: 177.77\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 12 is 2021-08-23 11:00:09.010247\n",
            "| epoch  12 |   100/  165 batches | lr 20.00000 | ms/batch 52.13 | loss  5.39 | ppl   220.06 | bpc    7.782\n",
            "Validation loss: 5.19. Perplexity: 179.10\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 13 is 2021-08-23 11:00:18.842770\n",
            "| epoch  13 |   100/  165 batches | lr 2.50000 | ms/batch 51.26 | loss  5.33 | ppl   205.59 | bpc    7.684\n",
            "Validation loss: 5.11. Perplexity: 165.29\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 14 is 2021-08-23 11:00:28.703151\n",
            "| epoch  14 |   100/  165 batches | lr 2.50000 | ms/batch 51.94 | loss  5.33 | ppl   206.38 | bpc    7.689\n",
            "Validation loss: 5.10. Perplexity: 164.42\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 15 is 2021-08-23 11:00:38.576599\n",
            "| epoch  15 |   100/  165 batches | lr 0.31250 | ms/batch 53.14 | loss  5.31 | ppl   201.63 | bpc    7.656\n",
            "Validation loss: 5.10. Perplexity: 164.14\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 16 is 2021-08-23 11:00:48.467530\n",
            "| epoch  16 |   100/  165 batches | lr 0.03906 | ms/batch 51.54 | loss  5.31 | ppl   201.71 | bpc    7.656\n",
            "Validation loss: 5.10. Perplexity: 164.07\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 17 is 2021-08-23 11:00:58.323287\n",
            "| epoch  17 |   100/  165 batches | lr 0.00488 | ms/batch 53.36 | loss  5.31 | ppl   201.85 | bpc    7.657\n",
            "Validation loss: 5.10. Perplexity: 164.06\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 18 is 2021-08-23 11:01:08.203625\n",
            "| epoch  18 |   100/  165 batches | lr 0.00061 | ms/batch 53.34 | loss  5.31 | ppl   201.79 | bpc    7.657\n",
            "Validation loss: 5.10. Perplexity: 164.06\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n",
            "Time at the start of epoch 19 is 2021-08-23 11:01:18.082896\n",
            "| epoch  19 |   100/  165 batches | lr 0.00008 | ms/batch 52.18 | loss  5.30 | ppl   201.24 | bpc    7.653\n",
            "Validation loss: 5.10. Perplexity: 164.06\n",
            "checkpoint saved to drive/MyDrive/chekpoints/checkpoints.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x020PJiFW81f"
      },
      "source": [
        "evaluate number agreement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS9ekN0CW7DH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "eb263137-0cd3-4a3e-bd59-dc043abeb319"
      },
      "source": [
        "# Test number agreeement task on a pre-trained model.\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--checkpoint', type=str, default='drive/MyDrive/chekpoints/checkpoints.pkl',\n",
        "        help='path to the checkpoint.')\n",
        "parser.add_argument('--gold-file', type=str, default='drive/MyDrive/num_agr/subj_agr_filtered.gold',\n",
        "        help='path to file containing context size, right target and wrong target.')\n",
        "parser.add_argument('--text-file', type=str, default='drive/MyDrive/num_agr/subj_agr_filtered.text',\n",
        "        help='path to file containing the sentences.')\n",
        "parser.add_argument('--nonce', action='store_true',\n",
        "        help='if provided, indicates the dataset is')\n",
        "parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "\n",
        "class Word2idx():\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "    def __call__(self, word):\n",
        "        if word in self.vocab:\n",
        "            return self.vocab[word]\n",
        "        else:\n",
        "            return self.vocab['<unk>']\n",
        "\n",
        "def tokenize(path, word2idx):\n",
        "    assert os.path.exists(path)\n",
        "    with open(path, 'r', encoding=\"utf8\") as f:\n",
        "        idss = []\n",
        "        lengths = []\n",
        "        for line in f:\n",
        "            words = line.split()\n",
        "            lengths.append(len(words))\n",
        "            ids = [word2idx(word) for word in words]\n",
        "            idss.append(torch.tensor(ids).type(torch.int64))\n",
        "        ids = torch.cat(idss)\n",
        "    return ids, lengths\n",
        "\n",
        "def batchify1(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data\n",
        "\n",
        "def result_(row, logits, word2idx):\n",
        "    # 1 represents that it succeded at the number agreement task, 0\n",
        "    # represents it didn't.\n",
        "    print(row)\n",
        "    logits = logits[row['idx'],0]\n",
        "    right = word2idx(row['right'])\n",
        "    wrong = word2idx(row['wrong'])\n",
        "    print(logits)\n",
        "    print(right)\n",
        "    print(wrong)\n",
        "    if logits[right] > logits[wrong]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def nonce_gold(path):\n",
        "    nonce_df = pd.read_csv(path, delimiter='\\t')\n",
        "    gold_df = pd.DataFrame()\n",
        "    gold_df[['context','right']] = nonce_df.loc[nonce_df['class'] == 'correct',\n",
        "                                    ['len_prefix', 'form']].reset_index(drop=True)\n",
        "    gold_df[['wrong','attractors']] = nonce_df.loc[nonce_df['class'] == 'wrong',\n",
        "                                    ['form', 'n_attr']].reset_index(drop=True)\n",
        "    return gold_df\n",
        "\n",
        "def main(arguments):\n",
        "    # Get the data we need from the checkpoint\n",
        "    model, corpora = load_model_corpora(arguments.checkpoint)\n",
        "    # load the sentences\n",
        "    word2idx = Word2idx(corpora.vocab)\n",
        "    sentences, lengths = tokenize(arguments.text_file, word2idx)\n",
        "    lengths = np.cumsum([0] + lengths[:-1])\n",
        "    if arguments.nonce:\n",
        "        gold = nonce_gold(arguments.gold_file)\n",
        "    else:\n",
        "        # load the number agreement data, which should be tab sepparated.\n",
        "        gold = pd.read_csv(arguments.gold_file, delimiter='\\t',\n",
        "                    names=['context','right','wrong','attractors'])\n",
        "    # Get the location of the target verbs.\n",
        "    gold['idx'] = gold['context'] + lengths\n",
        "    # Get the predictions.\n",
        "    model.eval()\n",
        "    sentences = batchify1(sentences, 1)\n",
        "    hidden = model.init_hidden(1)\n",
        "    input, _ = get_batch(sentences, 0, len(sentences))\n",
        "    output, hidden = model(input, hidden)\n",
        "    results = gold.apply(lambda x: result_(x, output, word2idx), axis=1)\n",
        "    checkpoint = load_checkpoint(arguments.checkpoint)\n",
        "    return results, checkpoint['valid_loss']\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parser.parse_args()\n",
        "    results, _ = main(args)\n",
        "    print(sum(results), len(results), sum(results)/len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "AWD  [WeightDrop(\n",
            "  (module): LSTM(350, 350)\n",
            "), WeightDrop(\n",
            "  (module): LSTM(350, 350)\n",
            ")]\n",
            "context        11\n",
            "right          is\n",
            "wrong         are\n",
            "attractors      0\n",
            "idx            11\n",
            "Name: 0, dtype: object\n",
            "tensor(0.0070, grad_fn=<SelectBackward>)\n",
            "3964\n",
            "1894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ff7476afad3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ff7476afad3a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ff7476afad3a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ff7476afad3a>\u001b[0m in \u001b[0;36mresult_\u001b[0;34m(row, logits, word2idx)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3964 is out of bounds for dimension 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjPDUdoVX-lY"
      },
      "source": [
        "training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erRnwIqhX9Wv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "4f01e392-4cb2-4794-f246-37bb502843a6"
      },
      "source": [
        "# Plot training curves of different training instances saved in a directory.\n",
        "# Also serves as a small library of useful functions for my plots.\n",
        "\n",
        "description_keys = {'dropout','hidden_size','clip_grad',\n",
        "                    'dataset_portion', 'old_model'}\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--directory', type=str, default= \"drive/MyDrive/logs/\", help='directory of description file')\n",
        "parser.add_argument('--logs', type=str, nargs='+')\n",
        "parser.add_argument('--description', type=str, \n",
        "                    default='description.txt', help='filename of description'\n",
        "                    'file if one is required.')\n",
        "parser.add_argument('--description-only', action='store_true')\n",
        "parser.add_argument('--plot-name', type=str, default='plot.png')\n",
        "parser.add_argument(\"-f\", \"--file\", required=False)\n",
        "\n",
        "def plot_curves(df_dict, fname='plot.png', x_axis='time'):\n",
        "    column = 'perplexity'\n",
        "    for name, df in df_dict.items():\n",
        "        plt.plot(df[x_axis], df[column], label = name)\n",
        "    plt.legend()\n",
        "    plt.xlabel(x_axis)\n",
        "    plt.ylabel(column)\n",
        "    plt.savefig(fname)\n",
        "\n",
        "def relative_time(df):\n",
        "    \"\"\" Make the time be 0 at the beginning of training,\n",
        "        and turn it into minutes \"\"\"\n",
        "    df.time = (df.time - df.time[0])/60\n",
        "    return df[1:]\n",
        "\n",
        "def load_dfs(dirs, names, file='valid.csv'):\n",
        "    assert len(dirs) == len(names)\n",
        "    dfs = dict()\n",
        "    for name, dir in zip(names, dirs):\n",
        "        filename = os.path.join(dir,name)\n",
        "        dfs[name] = relative_time(pd.read_csv(filename))\n",
        "    return dfs\n",
        "\n",
        "def check_dir(path, test_file='valid.csv'):\n",
        "    if os.path.isdir(path):\n",
        "        # check test file is in the directory\n",
        "        if test_file in os.listdir(path):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_dirs(directory, names=[], test_file='valid.csv'):\n",
        "    if len(names)==0:\n",
        "        names = os.listdir(directory)\n",
        "    dirs = []\n",
        "    for name in names.copy():\n",
        "        if check_dir(directory, name):\n",
        "            dirs.append(directory)\n",
        "        else:\n",
        "            names.remove(name)\n",
        "    return dirs, names\n",
        "\n",
        "def descriptions(dirs, file_to='description.txt', filename='description.txt'):\n",
        "    with open(file_to, 'w') as fout:\n",
        "        for dir in dirs:\n",
        "            file_in = os.path.join(dir, filename)\n",
        "            fout.write(dir + '\\n')\n",
        "            with open(file_in, 'r') as fin:\n",
        "                for line in fin:\n",
        "                    key = line.split(':')[0]\n",
        "                    if key in description_keys:\n",
        "                        fout.write(line)\n",
        "            fout.write('\\n')\n",
        "\n",
        "def get_attributes(dirs, names, attributes, filename='description.txt'):\n",
        "    dict = {}\n",
        "    for dir,name in zip(dirs,names):\n",
        "        file_in = os.path.join(dir, filename)\n",
        "        dict[name] = {}\n",
        "        with open(file_in, 'r') as fin:\n",
        "            for line in fin:\n",
        "                line = line.split(':')\n",
        "                key = line[0]\n",
        "                if key in attributes:\n",
        "                    dict[name][key] = line[1].strip()\n",
        "\n",
        "    return dict\n",
        "\n",
        "if __name__=='__main__':\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    directory = args.directory\n",
        "    if args.logs:\n",
        "        dirs, names = get_dirs(directory, args.logs)\n",
        "    else:\n",
        "        dirs, names = get_dirs(directory)\n",
        "    if args.description:\n",
        "        descriptions(dirs, file_to=args.description)\n",
        "    if not args.description_only:\n",
        "        df_dict = load_dfs(dirs, names)\n",
        "        plot_curves(df_dict, args.plot_name, 'epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4f59a2735738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mdescriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mplot_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-4f59a2735738>\u001b[0m in \u001b[0;36mload_dfs\u001b[0;34m(dirs, names, file)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-4f59a2735738>\u001b[0m in \u001b[0;36mrelative_time\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\" Make the time be 0 at the beginning of training,\n\u001b[1;32m     28\u001b[0m         and turn it into minutes \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'time'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NcgHJIZx7G"
      },
      "source": [
        "Plot NUmber agreement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg1LjhmgZwLX"
      },
      "source": [
        "# Plot the perplexity of models against their performance on Linzen's\n",
        "# number agreement task. Different markers for old and new model.\n",
        "plt.rcParams.update({'font.size': 13})  \n",
        "\n",
        "dir_new = 'train_data'\n",
        "dir_old = 'train_data/normal'\n",
        "\n",
        "dirs_new, _ = get_dirs(dir_new)\n",
        "dirs_old, _ = get_dirs(dir_old)\n",
        "\n",
        "def load_obj(dir, filename='num_agr_result.pkl'):\n",
        "    path = os.path.join(dir, filename)\n",
        "    with open(path, 'rb') as f:\n",
        "        dict_ = pickle.load(f)\n",
        "    return dict_\n",
        "\n",
        "proportion = lambda x: sum(x)/len(x)\n",
        "\n",
        "dicts_new = [load_obj(dir) for dir in dirs_new]\n",
        "dicts_old = [load_obj(dir) for dir in dirs_old]\n",
        "\n",
        "ppl_new = [d['perplexity'] for d in dicts_new]\n",
        "ppl_old = [d['perplexity'] for d in dicts_old]\n",
        "\n",
        "num_agr_new = [proportion(d['results']) for d in dicts_new]\n",
        "num_agr_old = [proportion(d['results']) for d in dicts_old]\n",
        "\n",
        "\n",
        "plt.plot(ppl_new, num_agr_new, 'rx', label='enhanced model')\n",
        "plt.plot(ppl_old, num_agr_old, 'bo', label='baseline model')\n",
        "plt.xlabel('validation perplexity')\n",
        "plt.ylabel('number agreement accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('num_agr.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG_k_WboauyZ"
      },
      "source": [
        "Plot Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ImWqUsgatmH"
      },
      "source": [
        "# Plot the final validation perplexity of old and new models against the\n",
        "# portion of the dataset used for training.\n",
        "\n",
        "attributes = ['old_model','dataset_portion']\n",
        "dir = 'train_data/half'\n",
        "\n",
        "plt.rcParams.update({'font.size': 13})  \n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--measure', default='perplexity', choices=['num_agr','perplexity'])\n",
        "parser.add_argument('--complete-baseline', type=str)\n",
        "parser.add_argument('--complete-enhanced', type=str)\n",
        "args = parser.parse_args()\n",
        "\n",
        "def load_obj(dir, filename='num_agr_result.pkl'):\n",
        "    path = os.path.join(dir, filename)\n",
        "    with open(path, 'rb') as f:\n",
        "        dict_ = pickle.load(f)\n",
        "    return dict_\n",
        "\n",
        "proportion = lambda x: sum(x)/len(x)\n",
        "\n",
        "def accuracies(dirs, names, filename='num_agr_result.pkl'):\n",
        "    results = [load_obj(dir)['results'] for dir in dirs]\n",
        "    return [proportion(result) for result in results]\n",
        "\n",
        "def perplexities(dirs, names, filename='num_agr_result.pkl'):\n",
        "    return [load_obj(dir)['perplexity'] for dir in dirs]\n",
        "\n",
        "dirs, names = get_dirs(dir)\n",
        "if args.measure == 'num_agr':\n",
        "    values = accuracies(dirs, names)\n",
        "else:\n",
        "    values = perplexities(dirs, names)\n",
        "\n",
        "if args.complete_baseline:\n",
        "    assert not args.complete_enhanced is None\n",
        "    complete_b = np.array(perplexities(*get_dirs(args.complete_baseline)))\n",
        "    complete_e = np.array(perplexities(*get_dirs(args.complete_enhanced)))\n",
        "    complete = True\n",
        "else:\n",
        "    complete = False\n",
        "\n",
        "attribs = get_attributes(dirs, names, attributes)\n",
        "portion_values = [attribs[name]['dataset_portion'] for name in names]\n",
        "\n",
        "old = [attribs[name]['old_model'] == 'True' for name in names]\n",
        "new = [not val for val in old]\n",
        "\n",
        "# Separate accuracies and portions into old and new\n",
        "new_pairs = [(a,b) for a,b,c in zip(values, portion_values, new) if c]\n",
        "old_pairs = [(a,b) for a,b,c in zip(values, portion_values, old) if c]\n",
        "\n",
        "if complete:\n",
        "    new_pairs.append((complete_e.mean(), '1.0'))\n",
        "    old_pairs.append((complete_b.mean(), '1.0'))\n",
        "\n",
        "# Sort the accuracies based on the portion used in training.\n",
        "new_pairs = sorted(new_pairs, key = lambda x: x[1])\n",
        "old_pairs = sorted(old_pairs, key = lambda x: x[1])\n",
        "\n",
        "def unzip(array, i):\n",
        "    return [tuple_[i] for tuple_ in array]\n",
        "\n",
        "portions = unzip(new_pairs, 1)\n",
        "\n",
        "new_accs = unzip(new_pairs, 0)\n",
        "old_accs = unzip(old_pairs, 0)\n",
        "\n",
        "fname = 'dataset_size.png'\n",
        "\n",
        "# Make the plot.\n",
        "xs = range(len(portions))\n",
        "plt.plot(xs,old_accs,'o--b', label='baseline model')\n",
        "plt.plot(xs,new_accs,'o--r', label='enhanced model')\n",
        "plt.ylabel('number agreement accuracy')\n",
        "plt.xlabel('portion of dataset used in training')\n",
        "plt.xticks(xs, portions)\n",
        "plt.legend()\n",
        "plt.savefig(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fN-Jy6CV45Q"
      },
      "source": [
        "Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7zWJzzJV10K"
      },
      "source": [
        "\n",
        "\n",
        "def nonce_gold(path):\n",
        "    nonce_df = pd.read_csv(path, delimiter='\\t')\n",
        "    gold_df = pd.DataFrame()\n",
        "    gold_df[['context','right','type']] = nonce_df.loc[nonce_df['class'] == 'correct',\n",
        "                                    ['len_prefix', 'form', 'type']].reset_index(drop=True)\n",
        "    gold_df[['wrong','attractors']] = nonce_df.loc[nonce_df['class'] == 'wrong',\n",
        "                                    ['form', 'n_attr']].reset_index(drop=True)\n",
        "    return gold_df\n",
        "\n",
        "def load_results(dir, filename='num_agr_result.pkl'):\n",
        "    \"\"\" Extract the results of the number agreement task from the directory.\n",
        "        filename is the name of the file in which they were stored.\n",
        "    \"\"\"\n",
        "    path = os.path.join(dir, filename)\n",
        "    with open(path, 'rb') as f:\n",
        "        dict_ = pickle.load(f)\n",
        "    return dict_['results']\n",
        "\n",
        "\n",
        "def results_dataframe(dir, gold_path = 'num_agr/subj_agr_filtered.gold',\n",
        "                            file_path = 'num_agr_result.pkl', nonce=False):\n",
        "    \"\"\" Create a dataframe with information of each test sentence for the number\n",
        "        agreement task, and whether it was predicted right by each saved model\n",
        "        in dir with stored results.\n",
        "    \"\"\"\n",
        "    dirs, names = get_dirs(dir, test_file=file_path)\n",
        "    # Load the information about the sentences as a dataframe\n",
        "    if nonce:\n",
        "        gold = nonce_gold(gold_path)\n",
        "    else:\n",
        "        gold = pd.read_csv(gold_path, delimiter='\\t',\n",
        "                    names=['context','right','wrong','attractors'])\n",
        "    # Load the results for each instance trained.\n",
        "    results = [load_results(dir, file_path) for dir in dirs]\n",
        "    # Add the results to the dataframe\n",
        "    for name,result in zip(names,results):\n",
        "        gold[name] = result\n",
        "    return gold, names\n",
        "\n",
        "def num_attractors_df(gold_df, names):\n",
        "    \"\"\" names = name of columns with results (abstractly represent a model).\n",
        "        gold_df = a dataframe with columns names and 'attractors'.\n",
        "        returns dataframe with attractors as index and the performance of each\n",
        "        model.\n",
        "    \"\"\"\n",
        "    new_df = gold_df[names + ['attractors']].groupby('attractors')\\\n",
        "                    .aggregate(['sum','count'])\n",
        "    new_df = new_df.swaplevel(axis=1)\n",
        "    indices = list(zip(['proportion']*len(names),names))\n",
        "    # Get the proportion of correct answers for each number of attractors.\n",
        "    new_df[indices] = new_df['sum']/new_df['count']\n",
        "    return new_df.swaplevel(axis=1)\n",
        "\n",
        "proportion = lambda x: sum(x)/len(x)\n",
        "\n",
        "def performance_df(gold_df, names):\n",
        "    \"\"\" Return dataframe with overall performance for each of names \"\"\"\n",
        "    performances = [proportion(gold_df[name]) for name in names]\n",
        "    new_df = pd.DataFrame(data=[performances],columns=names)\n",
        "    return new_df\n",
        "\n",
        "def get_stats(df, column='proportion', swaplevels=True):\n",
        "    \"\"\" return the mean and standard deviation of for columns with column as a\n",
        "        level (assumes multiindex columns).\n",
        "    \"\"\"\n",
        "    if swaplevels:\n",
        "        df = df.swaplevel(axis=1)\n",
        "    values = df[column]\n",
        "    return values.mean(axis=1).to_numpy(), values.std(axis=1).to_numpy()\n",
        "\n",
        "def plot_num_attractors(attractors_new, attractors_old,\n",
        "                        plot_name='acc_attractors.png'):\n",
        "    \"\"\" Plot and save plot of variation of performance and corresponding std for\n",
        "        input dataframes, as the number of attractors changes. Returns the\n",
        "        matplotlib.pyplot.axes with the plot.\n",
        "    \"\"\"\n",
        "    plt.rcParams.update({'font.size': 13})\n",
        "    # Get the index and check\n",
        "    xs = list(attractors_new.index)\n",
        "    assert list(attractors_old.index) == xs\n",
        "    means_new, stds_new = get_stats(attractors_new)\n",
        "    means_old, stds_old = get_stats(attractors_old)\n",
        "    # Make the plot\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.errorbar(xs, means_new*100, fmt='o-r', yerr=stds_new*100,\n",
        "                label='enhanced model', capsize = 5)\n",
        "    ax.errorbar(xs, means_old*100, fmt='o-b', yerr=stds_old*100,\n",
        "                label='baseline model', capsize = 5)\n",
        "    ax.set_xticks(xs)\n",
        "    ax.set_xlabel('number of attractors')\n",
        "    ax.set_ylabel('accuracy')\n",
        "    ax.grid(axis='y')\n",
        "    ax.legend()\n",
        "    plt.savefig(plot_name)\n",
        "    return ax\n",
        "\n",
        "def make_plot(old_dir, new_dir, gold_path = 'num_agr/subj_agr_filtered.gold',\n",
        "             file_path = 'num_agr_result.pkl', nonce=False):\n",
        "    new_df, new_names = results_dataframe(new_dir, gold_path, file_path, nonce)\n",
        "    old_df, old_names = results_dataframe(old_dir, gold_path, file_path, nonce)\n",
        "\n",
        "    new_df = num_attractors_df(new_df, new_names)\n",
        "    old_df = num_attractors_df(old_df, old_names)\n",
        "\n",
        "    return plot_num_attractors(new_df, old_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElbdvvQB7q9P"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}